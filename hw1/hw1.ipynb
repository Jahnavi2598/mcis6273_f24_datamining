{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "MCIS6273 Data Mining (Prof. Maull) / Fall 2024 / HW1\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 40 | Monday November 25 @ Midnight | _up to_ 20 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Perfom basic data engineering and visualization in Python using an external set data.\n", "\n", "* Perfom basic data analysis in Python your data file.\n", "\n", "* Perform basic K-Means clustering of cookie data.\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw0`.   Put all of your files in that directory.  Then zip or tar that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw0_files.zip`, `maull_hw0_files.tar.gz`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (30%) Perfom basic data engineering and visualization in Python using an external set data. \n", "\n", "Like last homework, you will continue your practice of data engineering to\n", "prepare data for analysis.  \n", "\n", "This time, we will get a little more exposure using a real dataset.\n", "\n", "For this part, we will be using data from [Open Food Facts (OFF)](https://openfoodfacts.org),\n", "which is  a non-profit organization and online platform that provides a comprehensive database of food products from around the world. The database includes information on over 1 million food products from more than 200 countries.\n", "\n", "While I would love to analyze the entire dataset, you will know that\n", "the full CSV dump of the data is 9GB and over 3.5 million rows of data!\n", "Far too much data for us to go through in a short assignent.\n", "\n", "In this first part, we will perform some data engineering as per usual,\n", "but to spoil the suprise, we will be analyzing the _cookies_ in the dataset\n", "so this first part is designed to actually work with a random subset \n", "that I have provided and made available on Github.\n", "\n", "Remember too, that all of your code must be implemented in Jupyter as a notebook -- you\n", "will be required to turn in a `.ipynb` file.\n", "\n", "**&#167; Task:**  **Filter data to a subset for further use.**\n", "Normally we would like to get the data and work with it directly, \n", "but I have had to reduce the size and scope for you.  But, \n", "if you are at all curious, you will visit [https://world.openfoodfacts.org/data](https://world.openfoodfacts.org/data) and\n", "download the 9GB file and play with it.  DO NOT do this on\n", "the HUB -- your account does not have enough disk space\n", "and will cause serious problems for you to be able to\n", "run other notebooks.  Do this on your own computers and know\n", "you will need considerable amounts of free RAM (>32GB minimum).\n", "\n", "\n", "I have created a file `en.openfoodfacts.products.cookies.csv.tar.gz` and\n", "in it are ~37k lines of data which are just cookies.  This file\n", "is on the Github for `hw1`: [https://github.com/kmsaumcis/mcis6273_f24_datamining/tree/main/hw0](https://github.com/kmsaumcis/mcis6273_f24_datamining/tree/main/hw0).  It is compressed\n", "so you will need to grab it an decompress it with `!tar xvzf en.openfoodfacts.products.cookies.csv.tar.gz`\n", "in a notebook cellpw.\n", "As a side note,\n", "this is only about 1% of the data, and you can think about how many cookies\n", "are in the world to consider the scope of that number!\n", "\n", "\n", "Now that you have a useful file, we will want to filter it further so \n", "we can restrict it to just the data we are interested in.\n", "\n", "Specifically, we want only a subset the data so that we can \n", "ignore data that we do not need.\n", "\n", "Load your `en.openfoodfacts.products.cookies.csv` and do some filtering as such:\n", "\n", "*  filter from the following countries only:\n", "    \n", "    * `'United States', 'France', 'Spain', 'United Kingdom', 'Canada', 'Italy', 'Australia', 'Switzerland', 'Brazil', 'India'`\n", "  * filter the data to just the following columns:\n", "    * `'countries_en', 'completeness', 'serving_size', 'energy-kcal_100g', 'fat_100g', 'saturated-fat_100g', 'trans-fat_100g', 'cholesterol_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'proteins_100g', 'sodium_100g', 'vitamin-a_100g', 'vitamin-d_100g', 'vitamin-e_100g', 'vitamin-k_100g', 'vitamin-c_100g', 'vitamin-b1_100g', 'vitamin-b2_100g', 'vitamin-pp_100g', 'vitamin-b6_100g', 'vitamin-b9_100g', 'folates_100g',  'vitamin-b12_100g', 'potassium_100g', 'calcium_100g', 'iron_100g', 'magnesium_100g', 'zinc_100g', 'copper_100g',  'manganese_100g', 'iodine_100g', 'caffeine_100g'   `\n", "  * filter the data further so that you only include data with `completeness` > 0.60\n", "  * finally filter the data so that `energy-kcal_100` > 0.0\n", "  * name the final file  `cookies.data-filtered.csv`\n", "\n", "\n", "**&#167; Task:**  **Plot the data**\n", "\n", "Produce the following 2 plots:\n", "\n", "* plot a bar plot of the frequency counts of cookies by country (use the `countries_en` column); study [`DataFrame.value_counts()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.value_counts.html#pandas.DataFrame.value_counts) to understand how to do this\n", "* bin the `completeness` column into 5 bins using [`pandas.cut`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html), plot the frequency of the completeness bins using a bar plot\n", "\n", "\n", "To do these plots please study [`DataFrame.plot()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html#pandas.DataFrame.plot).  This will \n", "provide all you will need to do what is expected. You\n", "will need to only use the data in the `countries_en` column.\n", "\n", "\n", "\n", "### (30%) Perfom basic data analysis in Python your data file. \n", "\n", "Now that we have some sample data (cookies from the countries of interest)\n", "we are going to do a little more data normalization to do analysis.\n", "\n", "If you look at the data, you might notice that most columns\n", "have numeric data, but one of the most useful columns `serving_size`\n", "has some very poor quality.\n", "\n", "We will produced one more file which will be the **final** file\n", "and then we will do some analysis thereafter.\n", "\n", "**&#167; Task:**  **Clean up the `serving_size` column and normalize it to numeric data only**\n", "\n", "If you notice there is some variation in the data entry\n", "for `serving_size` ... sometimes it is `'10g'`, others `'10 g'`\n", "and others are EU decimals like `'2,5g'` using commas and others \n", "using periods like `'2.5g'`.  There are some serious issues that\n", "need to be addressed since the value should just be a number.  We won't\n", "be able to fix all variations, but many can be addressed with\n", "a bit of normalization.\n", "\n", "You will need to normalize this so that it is just a floating point number.\n", "\n", "To do this you will need to study [`Series.str.match`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.match.html#pandas.Series.str.match)\n", "and [`Series.str.replace`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html#pandas.Series.str.replace).  To help you, \n", "the regular expression `r\"\\d+[\\W,.]?\\d*?g$\"` is\n", "sufficient for this part.  If\n", "this regular expression fails, you can ignore the data in that cell, and \n", "you may need to do a find `dropna()` based on that column to obtain\n", "your final results.  **NOTE:** your\n", "data will be reduced to a much smaller number of \n", "data points after `dropna()` on the column, but you\n", "should have between 1000-2000 data points\n", "left, so if you are in this ballpark, you are in good shape!\n", "\n", "Don't forget once done, you will need to use [`DataFrame.astype(float)`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html#pandas.DataFrame.astype) to coerce the data to a number.\n", "\n", "* save your final DataFrame into the final file called `cookies.data-filtered-final.csv`\n", "\n", "\n", "**&#167; Task:**  **Perform the descriptive statistics on the data.**\n", "\n", "You will need to study [`pandas.DataFrame.describe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html#pandas.DataFrame.describe)\n", "\n", "\n", "1. What is the mean and median `serving_size` over all cookies?\n", "2. What is the standard deviation of `cholesterol_100g`?\n", "3. Which are the top sweetest cookies normalized by `serving_size`.  **HINT:** take the `sugars_100g` divide by 100 and multiple by `serving_size` and sort accordingly.  Make sure to show the DataFrame for this.\n", "4. For all French cookies in your final data, what is the average `sugars_100g`? **HINT:** use the `countries_en` column.\n", "5. How does this compare to the United States?\n", "\n", "\n", "\n", "### (40%) Perform basic K-Means clustering of cookie data. \n", "\n", "One of the most robust clustering methods\n", "we can use in unsupervised learning is K-Means.\n", "\n", "The K-Means algorithm is a partitioning algorithm\n", "which clusters data into $k$ groups, and like\n", "the unsupervised algorithms in our toolkit, does\n", "not require any labeled data.  We can often\n", "use K-Means as a starting point for uncovering\n", "such labels (with some care).\n", "\n", "K-Means is summarized below.  The algorithm:\n", "\n", "* clusters data into $k$ groups with equal variance\n", "* minimizes \"inertia\" (within-cluster sum-of-squares)\n", "* requires number of clusters to be specified\n", "* scales well for large datasets, used in various fields\n", "* divides samples into disjoint clusters, each described by a centroid (mean)\n", "\n", "You will need to remember that:\n", "\n", "* by minimizing inertia, we end up with a measure for the internal coherence of clusters\n", "* centroids are not necessarily data points themselves\n", "* one of the drawbacks, is that it may have trouble  measuring internal cluster consistency\n", "\n", "Study the ScikitLearn documentation _carefully_:\n", "\n", "* [K-Means Clustering Algorithm](https://scikit-learn.org/stable/modules/clustering.html#k-means)\n", "\n", "**&#167; Task:**  **Using a cluster size $k=5$, perform K-Means clustering on the subset of columns\n", "provided.**\n", "\n", "We now have final dataset what we can work with and to do this last part, you will need to study the ScikitLearn\n", "K-Means clustering algorithm [KMeans Clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html).\n", "\n", "Simply provide the code that produces the clusters.\n", "\n", "You will need to reduce your date to just the following column attributes **before** you\n", "do the clustering:\n", "\n", "* `'serving_size', 'energy-kcal_100g', 'fat_100g', 'cholesterol_100g', 'carbohydrates_100g', 'sugars_100g', 'fiber_100g', 'proteins_100g', 'sodium_100g',  'vitamin-c_100g', 'vitamin-b12_100g', 'potassium_100g', 'calcium_100g', 'iron_100g'` \n", "\n", "\n", "**&#167; Task:**  **Provide a description of the centroids of each of the 5 clusters.**\n", "\n", "Your answer must include the description of each\n", "of the clusters by accessing the `cluster_centers_`, which are the\n", "the _centroids_ of the cluster.  See\n", "the documentation in ScikitLearn mentioned above.\n", "\n", "The centroids are the _representatives_ of each cluster,\n", "so we will (for now) let that stand as what type of\n", "cookie is in the cluster. \n", "\n", "Your answers will be similar  to the example given below, but will include mention of the\n", "relevant attribu:tes above\n", "\n", "> _Cluster #1 has a serving size of 2g, carbohydrate content of 20g and \n", "sugar content of 25g_\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}